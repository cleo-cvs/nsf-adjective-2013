\documentclass[10pt]{article}

\usepackage{fullpage}
\usepackage{palatino}


\begin{document}

\begin{center}
\vspace{-0.5em}
{\Large {\bf Project Summary}}\\*[3mm]
\vspace{-0.5em}
{\bf IIS-RI MEDIUM: 
Inference Discovery through Paired Annotation: A Case Study with Adjectives}\\\vskip .05in
%Lexical Inference Patterns for Adjectives in Natural Language}\\
{\bf PI: James Pustejovsky,  Inst: Brandeis University}; {\bf PI: Christiane Fellbaum,  Inst: Princeton University};
{\bf PI: Cleo Condoravdi,  Inst: Stanford University}; {\bf Co-PI: Daniel Lassiter,  Inst: Stanford University}
\end{center}

\vspace{-0.5em}
Effective communication relies heavily on the ability of language users to recover information that is not explicitly expressed in utterances. 
Much of the covert information can be identified as ``semantic inferences" associated with identifiable structural or lexical patterns.
An understanding of how speakers identify and exploit structural and lexical inference patterns has the potential to enrich models in theoretical linguistics. 
At the same time, it can support a major goal of current {\sc nlp} research: allowing natural language understanding systems to recover more of the rich semantic information encoded in the text. 
Did events mentioned in the text actually happen? 
Are they presented as being desirable? 
Which qualities are being ascribed to mentioned entities, or implied to hold of them?
Most previous work in this area has dealt with nouns and verbs; but a full answer to these questions will require careful attention to the the lexical semantics of adjectives. 
We propose to address the current lack of readily exploitable lexical information about adjectives in a large-scale, empirical investigation of semantic interactions among textual elements and comparing annotations from multiple sources. The specific aims of the proposal are:

\vspace{-0.4em}
\begin{itemize}

\item Develop an inferential model for adjectival semantics in natural language;

\vspace{-0.5em}
\item Use the model to bridge expert annotations over small corpora and raw data from large corpora using structure-to-inference mappings bolstered by recent machine learning techniques;

\vspace{-0.5em}
\item Crowdsource annotation using Amazon Mechanical Turk on similar tasks with larger textual contexts and sets of adjectives, constructing \textbf{paired annotations} with the goal of improving annotation methodologies and models of inference.
\end{itemize}

\vspace{-.5em}

We concentrate on three diverse classes of  adjectives, 
in order to (a) test the applicability of the methodology to different linguistic classes, and (b) highlight both common principles and divergences between structure-to-inference mappings across lexical classes. 
We will study
(i) dimensional and evaluative adjectives organized into scales, e.g., \textit{pretty, beautiful, large, huge}; 
(ii) clause-selecting adjectives with varying implications of veridicity, e.g., \textit{smart, annoying, likely}; 
(iii) intensional adjectives, introducing implicatures of modal subordination, e.g., \textit{alleged, supposed, so-called}. 
The work will result in a Gold standard inference corpus created using a standard linguistic annotation effort following explicit guidelines indicating the structure-to-inference mappings for each adjective type. 
We compare these baseline mappings to inferential judgments made by linguistically untrained native speakers. 
Preliminary studies suggest a variance from the expert baseline, caused by textual factors typically ignored in linguistic studies. 
We use these differential judgments (linguist vs. naive annotator) to classify the implicatures along two dimensions: (1) how stable an inference is regardless of linguistic context; (2) which contextual factors contribute to blocking the expected inference. 
We construct a model to gauge how well our distinctions explain the behavior of these speakers. This provides an account for the interactions of different structural and lexical factors. 

\vspace{-1.2em}
\paragraph{Intellectual Merit.} The proposed work 
develops and validates a methodology for the empirical discovery and exploitation of systematic inferences identified with three distinct classes of adjectives in natural language
and provides a novel and subtle analysis of these adjectives with sensitivity to their linguistic contexts. An important contribution will be a richer conceptualization 
of corpus and lexicon annotation with significant consequences for computational linguists. 

\vspace{-1.2em}
\paragraph{Broader Impact.}
The proposed work  makes several significant contributions to a broader community of computational linguists, AI researchers, and psychologists. 
Our work lays theoretical groundwork for large-scale annotation of three classes of adjectives in order to support automatic systems in inferencing tasks. 
A second contribution is a more sophisticated theory of the role of lexical information in human inferential behavior, a topic of considerable psychological interest.
Third, the work holds out the promise of developing new methodologies for large-scale annotation and combining experimental and corpus investigation that could benefit the development of more human-like systems for natural language understanding.
%One PI and one consultant are women, and female and minority students will be recruited for providing Gold standard judgments. 


\vspace{-1.2em}


\paragraph{Key Words:} Inferences, lexical-semantic patterns, adjective classes, corpus data, crowdsourcing. 


\end{document}




