\documentclass[10pt]{article}

\usepackage{fullpage}
\usepackage{palatino}


\begin{document}

\begin{center}
\vspace{-0.5em}
{\Large {\bf Project Summary}}\\*[3mm]
\vspace{-0.5em}
{\bf IIS-RI MEDIUM: 
Inference Discovery through Paired Annotation: A Case Study with Adjectives}\\\vskip .05in
%Lexical Inference Patterns for Adjectives in Natural Language}\\
{\bf PI: James Pustejovsky,  Inst: Brandeis University}; {\bf PI: Christiane Fellbaum,  Inst: Princeton University};
{\bf PI: Cleo Condoravdi,  Inst: Stanford University}; {\bf Co-PI: Daniel Lassiter,  Inst: Stanford University}
\end{center}

\vspace{-0.5em}
Effective communication relies heavily on the ability of language users to recover information that is not explicitly expressed in utterances. 
Much of the covert information can be identified as ``semantic inferences", and as such, be associated with identifiable structural or lexical patterns in natural language.
An understanding of how speakers identify and exploit systematic covert inferences in language has the potential to enrich our models of compositionally derived inferences. 
At the same time, it can enhance the capabilities of natural language understanding systems to read beyond the surface forms of the text, a major goals of current {\sc nlp} research. 
We address the ways speakers interpret texts with respect to the following questions: Did events referred to in the text in fact occur or not? 
Are they desirable? 
How do speakers interpret qualities ascribed to entities in a text? 
To answer subtle questions such as these, careful analysis of the lexical semantics of adjectives is needed. 
We propose to address the current lack of readily exploitable linguistic information for this category and to explore its modeling in a large-scale, empirical investigation considering the semantic interactions among textual elements and comparing linguistic judgments from linguistically trained and untrained (``na\"ive'') speakers. The specific aims of the proposal are:

\vspace{-0.4em}
\begin{itemize}

\item Develop an inferential model for adjectival semantics in natural language;

\vspace{-0.5em}
\item Use the model to bridge expert annotations over small corpora and raw data from large corpora using structure-to-inference mappings bolstered by recent machine learning techniques;

\vspace{-0.5em}
\item Crowdsource annotation using Amazon Mechanical Turk in order to collect human data on similar tasks using larger textual contexts and larger sets of adjectives than is practical using trained annotators, with the goal of improving methodologies for non-expert linguistic annotation.
\end{itemize}

\vspace{-.5em}

We concentrate on three diverse classes of  adjectives, 
in order to (a) test the applicability of the methodology to different linguistic classes, and (b) highlight both common principles and divergences between structure-to-inference mappings across lexical classes. 
We will study
(i) dimensional and evaluative adjectives organized into scales, e.g., \textit{pretty, beautiful, large, huge}; 
(ii) clause-selecting adjectives with varying implications of veridicity, e.g., \textit{smart, annoying, likely}; 
(iii) intensional adjectives, introducing implicatures of modal subordination, e.g., \textit{alleged, supposed, so-called}. 
The work will result in a Gold standard inference corpus created using a standard linguistic annotation effort following explicit guidelines indicating the structure-to-inference mappings for each adjective type. 
We compare these baseline mappings to inferential judgments made by linguistically untrained native speakers. 
Preliminary studies suggest a variance from the expert baseline, caused by textual factors typically ignored in linguistic studies. 
We use these differential judgments (linguist vs. naive annotator) to classify the implicatures along two dimensions: (1) how stable an inference is regardless of linguistic context; (2) which contextual factors contribute to blocking the expected inference. 
We construct a model to gauge how well our distinctions explain the behavior of these speakers. This provides an account for the interactions of different structural and lexical factors. 

\vspace{-1.2em}
\paragraph{Intellectual Merit.} The proposed work 
develops and validates a methodology for the empirical discovery and exploitation of systematic inferences identified with three distinct classes of adjectives in natural language
and provides a novel and subtle analysis of these adjectives with sensitivity to their linguistic contexts. An important contribution will be a richer conceptualization 
of corpus and lexicon annotation with significant consequences for computational linguists. 

\vspace{-1.2em}
\paragraph{Broader Impact.}
The proposed work  makes several significant contributions to a broader community of computational linguists, AI researchers, and psychologists. 
Our work lays theoretical groundwork for large-scale annotation of three classes of adjectives in order to support automatic systems in inferencing tasks. 
A second contribution is a more sophisticated theory of the role of lexical information in human inferential behavior, a topic of considerable psychological interest.
Third, the work holds out the promise of developing new methodologies for large-scale annotation and combining experimental and corpus investigation that could benefit the development of more human-like systems for natural language understanding.
%One PI and one consultant are women, and female and minority students will be recruited for providing Gold standard judgments. 


\vspace{-1.2em}


\paragraph{Key Words:} Inferences, lexical-semantic patterns, adjective classes, corpus data, crowdsourcing. 


\end{document}




